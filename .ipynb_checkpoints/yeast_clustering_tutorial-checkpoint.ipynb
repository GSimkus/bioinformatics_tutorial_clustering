{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Microarray Data: A tutorial in unsupervised machine learning\n",
    "\n",
    "![A DNA Microarray](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/DNA_microarray.svg/500px-DNA_microarray.svg.png)\n",
    "\n",
    "This is a tutorial that demonstrates some high-level concepts in bioinformatics, undirected machine learning, and data visualization. In particular, it performs a K-means clustering analysis on microarray data from 6153 genes at 7 time points, and demonstrates several methods for visualizing the resulting data.\n",
    "\n",
    "The code of this notebook is all written in Python 3, and a copy of this notebook is available at [My GitHub](https://github.com/GSimkus/bioinformatics_tutorial_clustering/).\n",
    "\n",
    "This page is a work-in-progress, please forgive any errors or areas which are unclear. You can send suggestions for how to improve it to the email address given on the aforementioned GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #dddddd; border-color: #cccccc; border-left: 4px solid #aaaaaa; padding: 0.5em;\">\n",
    "**To run this notebook on your own computer:**\n",
    "  <ol>\n",
    "  <li>Install a Python distribution such as [Anaconda](https://store.continuum.io/cshop/anaconda/), or separately download all of the dependencies listed in the readme file in [My GitHub](https://github.com/GSimkus/bioinformatics_tutorial_clustering/).</li>\n",
    "  <li>Download the source for this notebook to your computer from [here](https://github.com/GSimkus/bioinformatics_tutorial_clustering/blob/master/yeast_clustering_tutorial.ipynb) <br />\n",
    "  (Click the download button, then save the page as \"yeast_clustering_tutorial.ipynb\" and remove any \".txt\" that appears)</li>\n",
    "  <li>(Optional) Download and install FFMPEG by following [this guide](https://github.com/adaptlearning/adapt_authoring/wiki/Installing-FFmpeg). You'll need this to generate the animations at the end of the notebook </li>\n",
    "  <li>Launch \"Jupyter Notebook\", then select \"yeast_clustering_tutorial.ipynb\" in the browser</li>\n",
    "  </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first thing to do in any script is to \"import\" the libraries we'll use:\n",
    "\n",
    "While there are a number of extremely high quality libraries out there that can perform most of tasks we cover below, I wanted to provide some examples of simple, easy-to-follow code that you can write yourself. Instead of using a library like [scikit-learn](http://scikit-learn.org/stable/index.html), and running a command like \"sklearn.cluster.KMeans()\" and having everything handled for you; I want to show you how to design a machine learning algorithim from scratch, and to use it to learn things about real-life data.\n",
    "\n",
    "There are, however, a few things we *will* get help with - like rendering our graphs, working with math, and structuring the data itself - so that we can focus on the bioinformatics.\n",
    "\n",
    "In this case, the libraries we'll need are:\n",
    "* `math` which is python's built in library for doing math with. We will need the square root and ceiling functions.\n",
    "* `numpy` describes itself as \"the fundamental package for scientific computing with Python\". It's not wrong.\n",
    "* `pandas` is a library that makes working with structured data like tables much easier\n",
    "* `matplotlib` provides all sorts of tools for visualizing data, like animation, the module we import here\n",
    "\n",
    "Also being done here:\n",
    "* `%matplotlib inline` is a \"magic function\" in Jupyter that ensures that any plots we make in this notebook are rendered in the browser, in HTML.\n",
    "* `rc('animation', html='html5')` sets the rendering settings on the animations and videos to be compatible with a webbrowser\n",
    "* `np.random.seed(1)` sets the random number generator (which comes from numpy) to have a \"seed\" value of 1 (there's no reason it has to be 1). This means that the outputs will be the same every time we run this notebook, which is not only a good practice in science (since an experiment isn't worth much unless it's reproducible), but is very useful for this tutorial, since it ensures you and I will see the same results when we run the code.\n",
    "\n",
    "If you are running this on your own computer, you can run a cell and move to the next one by pressing shift and enter, or pressing the button to step forward at the top of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt, ceil\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import bar\n",
    "from matplotlib import animation, rc, cm\n",
    "\n",
    "%matplotlib inline\n",
    "rc('animation', html='html5')\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Next we will load our data and take a few peaks.\n",
    "\n",
    "The data we will be using today comes from a [DNA microarray](https://en.wikipedia.org/wiki/DNA_microarray) experiment performed by Joseph L. DeRisi, Vishwanath R. Iyer, and Patrick O. Brown in 1997.\n",
    "\n",
    "You can find all of the raw data in the \"[Gene Expression Omnibus](https://www.ncbi.nlm.nih.gov/geo/)\" database, which is maintained by NCBI. Our data specifically is [series GSE28](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE28).\n",
    "\n",
    "The series consists of yeast that was placed into an incubator and allowed to slowly run out of food. Samples were collected at the start, 9.5hours later, and then at the 11.5, 13.5, 15.5, 18.5, and 20.5 hour marks for a total of 7 timepoints.\n",
    "\n",
    "For each sample the amount of mRNA present for each of the 6153 yeast genes was measured, which tells us how much protein was produced for each and every one of those genes.\n",
    "\n",
    "I've taken the raw data from the website and done all of the processing already, for simplicity's sake I'm not including the process of compiling all of the raw machine output data values into a final dataset (at least for now, check back for updates!), and instead we'll skip right to the set I compiled myself and which is located on the [Github Repo](https://github.com/GSimkus/bioinformatics_tutorial_clustering/) where you (hopefully) downloaded this notebook from.\n",
    "\n",
    "#### A note on formatting:\n",
    "\n",
    "In my compiled data I have taken the ratio of the reading at every timepoint to the reference reading taken at the start of the experiment, and then taken the base 2 logarithm of those ratios.\n",
    "\n",
    "So 0 at any timepoint means no difference in the level of protein between that time and the start of the experiment, a -1 indicates half the level of expression, a +1 indicates twice the expression, a +2 indicates four times, etc.\n",
    "\n",
    "Each row in the dataset starts with a unique index number, from 0 to 6152, then contains the standard \"systematic\" name for the gene/protein, and the \"common\" name for the gene (which doesn't always exist, and many entries in this column read \"NaN\" or \"Not a Number\", which is used to fill in blanks).\n",
    "\n",
    "\n",
    "## Exploring the data\n",
    "To begin, we'll load the data. Pandas makes this easy with a \"read_csv\" function. Note that it doesn't matter that the file doesn't actually end in \".csv\" here, the function doesn't care as long as the file it's told to read is formatted similarly to a csv or \"comma-separated values\" file.\n",
    "\n",
    "So since my file contains nothing but values that are separated by commas for each column, and has a new line for every row, there's no issue; we can simply read the file with the function from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pandas.read_csv(\"dataset.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is loaded, we can start exploring it, yay!\n",
    "\n",
    "Now, since there are over 6000 rows I won't display it all at once (though if you are running this in your own notebook, feel free to do that).\n",
    "\n",
    "Instead, we can look at only the first few points of data by using `dataset.head()`, a handy feature provided by pandas. \n",
    "\n",
    "You can see the things I talked about above, the index number, the systematic name of the Open Reading Frame or \"ORF\", the common name for each gene, and a bunch of a numeric values - one value for each of the time points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also view a random sample of points with the `dataset.sample()`. Let's take 10 random rows and save them as a new variable, called \"sample\". You'll notice that when we do, the index numbers of our sample won't be in order anymore, a byproduct of the random selecting of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to pandas it's also easy to look at only the time columns, hiding the names of the genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints = [\"0\", \"9.5\", \"11.5\", \"13.5\", \"15.5\", \"18.5\", \"20.5\"]\n",
    "dataset[timepoints].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can get summaries like this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the standard deviation is very small compared to the min and max for each of the time points, and that our 25th, and 75th percentiles are very close to eachother. This suggests that the majority of data is all located in one region.\n",
    "\n",
    "## Visualizing the data\n",
    "\n",
    "It's all well and good to look at things like standard deviations and percentiles, but those are hard to immediately understand in the way that a graph is. \n",
    "\n",
    "We'll start with a histogram, drawing the 6 timepoints after the start of the experiment.\n",
    "\n",
    "We'll even make this a function, so we can use it later without re-typing it all.\n",
    "\n",
    "Read the comments (text after a \"#\") to follow along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first line is a function definition, we'll name it \"histograms\"\n",
    "# Our funciton will take a dataset, and make histograms out of it\n",
    "def histograms(dataset):\n",
    "    \n",
    "    # Creating an empty figure on which we will plot things\n",
    "    # the \"figsize=(15, 16)\" bit just set a custom size for\n",
    "    # the canvas, to prevent squishing\n",
    "    fig = plt.figure(figsize=(15,16))\n",
    "    \n",
    "    # Now we're going to go through every timepoint  *except* the first one \n",
    "    # and also number them. Python has a built-in \"enumerate\" function that\n",
    "    # assigns numbers to things, and we'll use a \"for\" loop to move through \n",
    "    # the timepoints and do our work. \n",
    "    for i, time in enumerate(timepoints[1:]):\n",
    "    \n",
    "        # add_subplot specifies a number of rows and columns that will be drawn,\n",
    "        # it also needs to be told which subplot is currently being worked on, \n",
    "        # which is what the i+1 is for. The +1 is necessary since enumerate starts\n",
    "        # on 0, but the top-left subplot is numbered 1. \n",
    "        fig.add_subplot(3,2,i+1)\n",
    "        \n",
    "        # Pretty simple, get the time column from the dataset and plot a histogram\n",
    "        # The histogram has 60 bins, and covers the range of -3 to 3\n",
    "        dataset[time].plot.hist(bins=60, range = (-3, 3))\n",
    "        \n",
    "        # Title the image\n",
    "        plt.title(\"{} hour timepoint\".format(time))\n",
    "        \n",
    "        # Set a standard y-axis height for easier comparison\n",
    "        plt.ylim([0,800])\n",
    "        \n",
    "# Now we'll call the function\n",
    "histograms(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can also visualize the distribution with a KDE plot, and the code is almost identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdes(dataset):\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 16))\n",
    "    \n",
    "    for i, time in enumerate(timepoints[1:]):\n",
    "        fig.add_subplot(3,2,i+1)\n",
    "        \n",
    "        dataset[time].plot.kde()\n",
    "        plt.title(\"{} hour timepoint\".format(time))\n",
    "        \n",
    "        plt.ylim([0,1.4])\n",
    "        plt.xlim([-3, 3])\n",
    "        \n",
    "        \n",
    "kdes(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even in the final timepoints **vast** majority of the genes never change expression very much.\n",
    "\n",
    "Since we're interested in the genes that are actually affected by starvation let's remove all the points whose expression never changes by more than, say, 40% (0.5 on our scale).\n",
    "\n",
    "We'll start by getting every row where *all* the values along the row axis (that is, along axis 1) have an absolute value of *less than* 0.5.\n",
    "\n",
    "Note: we also could look for where *not any* of the values is *greater* than 0.5\n",
    "\n",
    "In pseudo code I'm saying:\n",
    "\n",
    "\"Get the part of the whole dataset where ALL of the timepoint-columns in each row (axis=1) have absolute values less that 0.5\" and call it the \"duds\"\n",
    "\n",
    "In Python that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "duds = dataset[(dataset[timepoints].abs() < 0.5).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we may as well describe it, too\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duds.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, 867 genes that barely changed expression at all. Let's drop them from our data and then look at the new histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_data = dataset.drop(duds.index)\n",
    "histograms(trimmed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like most of the changes happen in the last 5 hours. Interestingly, the middle parts of the last 2 histograms, while smaller, are *not* completely empty. Huh.\n",
    "\n",
    "Maybe a different kind of graph would provide more insight. \n",
    "\n",
    "Since the data is made up of values and timepoints, it should be pretty easy to plot a line graph, but since pandas likes to plot with the \"index\" as the x axis, we're going to want to transpose the data, first.\n",
    "\n",
    "Since plotting 4000+ lines on one graph would be a complete mess, we'll plot a sample of 10 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we grab a sample, just like we did earlier but now with 20 points\n",
    "sample = trimmed_data.sample(10)\n",
    "\n",
    "# Then we transpose it\n",
    "transposed_sample = sample[timepoints].T\n",
    "\n",
    "# And finally we plot. The semicolon prevents that annoying text string from appearing\n",
    "transposed_sample.plot.line(legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha! It seems like many of the points jump around a lot, including a bunch that spike early and then drop back to 0. That means either this kind of variation is totally normal of *any* gene, **or** there's something interesting going on.\n",
    "\n",
    "Note: If we wanted to focus on just the extreme genes we *could* drop more data points, but it's possible that some of these shifts are important parts of the yeast's biology, and if we drop too much data we risk oversimplifying.\n",
    "\n",
    "That said, it would be nice to somehow categorize these patterns and get a list of proteins whose expression levels over time are similar.   \n",
    "For that we can use:\n",
    "## Unsupervised Machine Learning\n",
    "Specifically, the K-means clustering algorithm, sometimes called \"Lloyd's Algorithm\", which is a fast and very popular tool for clustering data into categories. It's far from perfect, with algorithms like the \"Expectation-Maximization clustering\" algorithim tending to obtain better results with more room for subtlety, but it's extremely fast and can be used in most scenarios with little to no issue.\n",
    "\n",
    "To see it in action, let's whip up some clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we'll pick some points to use as the true centers of the clusters\n",
    "xs, ys = [-9, -4, 9], [9, -6, 4]\n",
    "\n",
    "# Then we'll pick some sigma values\n",
    "sigmas = [4, 3, 4]\n",
    "\n",
    "# And finally create some blank lists\n",
    "xdata, ydata = [], []\n",
    "\n",
    "# All that's left is to make a few clusters with a for loop\n",
    "for i in range(3):\n",
    "    # We'll get a bunch of x and y coordinates from a normal distribution\n",
    "    coordsx = list(np.random.normal(xs[i], sigmas[i], (30)))\n",
    "    coordsy = list(np.random.normal(ys[i], sigmas[i], (30)))\n",
    "    \n",
    "    # Saving them for later\n",
    "    xdata += coordsx\n",
    "    ydata += coordsy\n",
    "    \n",
    "# Finally, we're going to \"zip\" together the x and y coordinates into a bunch of x,y points\n",
    "points = [(x, y) for x,y in zip(xdata, ydata)]\n",
    "\n",
    "# And add those points to a new DataFrame\n",
    "example = pandas.DataFrame(points, columns= [\"x\", \"y\"])\n",
    "example.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our points on a scatterplot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(example[\"x\"],example[\"y\"], \"o\", color='grey',  markersize = 4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good!\n",
    "\n",
    "The next step is to decide how many clusters we want out algorithim to find - the \"K\" in \"K-means\".\n",
    "\n",
    "I'm going to say 3, for what are hopefully obvious reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-means algorithm is fairly simple, it just has 3 steps:\n",
    "\n",
    "    1. Pick k points to use as centers of clusters\n",
    "    2. Put every point into a cluster with the center it is closest to\n",
    "    3. Move the centers to the middle of the clusters in the above step\n",
    "\n",
    "And then the algorithm repeats step 2 and 3 for however many times you want it to.\n",
    "\n",
    "Let's get started.\n",
    "\n",
    "### Step1: Pick a random set of points to be used as the centers of the first clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing 3 random rows from our example data\n",
    "sample = example.sample(k)\n",
    "\n",
    "# And getting the coordinates of those points out as a list\n",
    "centerslist = sample[[\"x\", \"y\"]].values\n",
    "\n",
    "#Finally, we'll plot the centers as big red stars on the same axis as the rest of the points\n",
    "ax.plot(centerslist.T[0],centerslist.T[1], '*', color = 'red', markersize = 15);\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: do a \"Points to Clusters\" step\n",
    "Every point is added to whatever cluster is closest, and we should make this a new function.\n",
    "\n",
    "We should first define a function that tells us the distance between points, and one that determines what center is closest to a given point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The distance between point 1 and point 2\n",
    "def distance(p1, p2):\n",
    "    # Is the cartesian distance between the points!\n",
    "     return sqrt(sum([(x-i)**2 for x,i in zip(p1, p2)]))\n",
    "\n",
    "# Point to Cluster takes a single point\n",
    "def p2c(point):\n",
    "    point = list(point)\n",
    "    # Looks at the distance to all the centers\n",
    "    distances = [distance(point, center) for center in centerslist]\n",
    "    #And returns the index of the smallest distance\n",
    "    return distances.index(min(distances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply this p2c function to every row in the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save some typing I will shorthand the columns I want to plot\n",
    "cols = [\"x\", \"y\"]\n",
    "\n",
    "example['Cluster'] = example[cols].apply(p2c, axis=1, raw=True)\n",
    "\n",
    "# Let's see the numbers of points in each cluster\n",
    "example.groupby(\"Cluster\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not great, each cluster should have exactly 40 points.\n",
    "Let's see the graph at this stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we'll need some distinct colors for the points and the chosen centers\n",
    "colors = ['fuchsia', 'orange', 'lime']\n",
    "centercolors = ['indigo', 'orangered', 'darkgreen']\n",
    "\n",
    "# We may as well define a new function.\n",
    "# The scatterplot function takes data and assumes \"k\" number of clusters\n",
    "def scatterplot(data, k=k):\n",
    "    \n",
    "    # Creates a drawing space and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Then  goes through a loop for each of k clusters\n",
    "    for i in range(k):\n",
    "    \n",
    "        # getting the rows of the points for each cluster\n",
    "        cluster = example[(example[\"Cluster\"] == i)]\n",
    "\n",
    "        # plotting the points\n",
    "        ax.plot(cluster.x, cluster.y, \"o\", label=\"Cluster {}\".format(i), color = colors[i], ms=4)\n",
    "\n",
    "        # and adding the centers again\n",
    "        ax.plot(centerslist.T[0][i],centerslist.T[1][i], '*', color = centercolors[i], markersize = 15);\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "# I'm only assigning fig and ax as variables because of some trickery I will employ later.\n",
    "fig, ax = scatterplot(example);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew, this is messy, everything happened to be in a vertical line, and the resulting clusters are nothing like what we want!  \n",
    "Let's hurry up and complete the algorithm.\n",
    "\n",
    "### Step 3: do a \"Clusters to Points\" step\n",
    "Move the center to the middle of the new cluster by finding the average of the entire cluster, and making that the new center point.\n",
    "\n",
    "*Sidenote: if the dataset was extremely large we could save time here by using some kind of Monte Carlo method to take a statistical sample of points and finding their average, which can dramatically speed up an already fast algorithm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We input the dataframe of our points       \n",
    "def c2p(data, columns):\n",
    "    \n",
    "    # Chuck out that old centerslist\n",
    "    centerslist = []\n",
    "    \n",
    "    # Go through all k centers\n",
    "    for i in range(k):\n",
    "        \n",
    "        # And add the mean of each coordinate in each column to the centerlist\n",
    "        centerslist += [data[(data.Cluster == i)][columns].mean().tolist()]\n",
    "    return np.array(centerslist)\n",
    "centerslist = c2p(example, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the function, defined and applied. Let's add these new centers as pentagons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k):\n",
    "    ax.plot(centerslist.T[0][i],centerslist.T[1][i], 'p', color = centercolors[i], markersize = 15);\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those centers look more appropriate. The green center has shifted upwards, and the orange center has moved right. Let's repeat steps 2 and 3 and then plot the graph again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we apply the p2c algorithm to all the rows\n",
    "example['Cluster'] = example[cols].apply(p2c, axis=1, raw=True)\n",
    "\n",
    "# Then we get new centers\n",
    "centerslist = c2p(example, cols)\n",
    "\n",
    "# And finally, we plot the new graph\n",
    "fig, ax = scatterplot(example);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's certainly getting there! We can repeat that process again to get the centers closer to their true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example['Cluster'] = example[cols].apply(p2c, axis=1, raw=True)\n",
    "centerslist = c2p(example, cols)\n",
    "\n",
    "for i in range(k):\n",
    "    ax.plot(centerslist.T[0][i],centerslist.T[1][i], 'p', color = centercolors[i], markersize = 15);\n",
    "scatterplot(example);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can loop the algorithm 20 more times, and it will improve with each loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    example['Cluster'] = example[cols].apply(p2c, axis=1, raw=True)\n",
    "    centerslist = c2p(example, cols)\n",
    "    \n",
    "scatterplot(example);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good!\n",
    "Feel free to change all the variables above and watch the process with different centers, numbers of clusters, standard deviations, etc.\n",
    "\n",
    "Otherwise, \n",
    "\n",
    "## It's time to get back to our main dataset\n",
    "\n",
    "We can choose any number of clusters we want, so let's choose something like 4 clusters for this data.\n",
    "I also think that typing \"trimmed_data\" all the time is going to be annoying, so we're going to just call it \"data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 4\n",
    "data = trimmed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to want a good list of colors to use. My favourite from [the standard set available in matplotlib](https://matplotlib.org/examples/color/colormaps_reference.html) is \"tab10\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = cm.tab10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we've got the \"p2c\" function already, we're ready to do the first 2 steps of the algorithm:\n",
    "\n",
    "### Step1:\n",
    "* Choose K rows, \n",
    "* get their coordinates into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = data.sample(k)\n",
    "centerslist = sample[timepoints].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2:  \n",
    "* Assign the rest of the points into clusters\n",
    "* We may as well take a look at counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cluster'] = data[timepoints].apply(p2c, axis=1, raw=True)\n",
    "data.groupby(\"Cluster\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've got our 5286 points arranged into 4 groups of various sizes, and it would be awesome to look at them, but unfortunately each row has 7 values, and since 7 is bigger than 2 it's not very easy to display my data on a screen.\n",
    "\n",
    "This is one of the [Curses of Dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality). We can't make those nice little 2D scatter plots when working with 7-dimensional data.\n",
    "\n",
    "Fortunately, we *can* plot a line graph from 7 points, and that's a starting point.\n",
    "\n",
    "Now like I mentioned above, to graph 5000+ lines would be to make an image that's completely incomprehensible, so how about we only plot the arithmetic mean of each cluster's expression at each time. \n",
    "\n",
    "And to be extra fancy, we'll add a semi-transparent area that shows one standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# I'm going to add a \"clusters_to_plot\" parameter with a default value of range k, which might be useful later.\n",
    "def plotmeans(data, clusters_to_plot = range(k)):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0, 0, 2, 1])\n",
    "    # That list there simply stretches the x axis out, it will make the graph look nicer.\n",
    "    \n",
    "    # I'm also tired of graphs with black lines on the top and left, let's remove those.\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    # A nice title, and some axis labels\n",
    "    plt.title(\"Clustered Yeast Expression Ratios\")\n",
    "    plt.xlabel(\"Time since innoculation\\n/h\")\n",
    "    plt.ylabel(\"Expression\\nRatio\", rotation = 0, labelpad = 25)\n",
    "    # the \"\\n\" is code for \"new line\"\n",
    "    \n",
    "    # This takes the list of column names and turns them into floats \n",
    "    # (aka numbers with decimals) so we can accurately plot time on the x axis\n",
    "    xdata=[float(i) for i in timepoints]\n",
    "    \n",
    "    # We'll also go ahead and set the axis to display those ticks\n",
    "    ax.set_xticks(xdata)\n",
    "    ax.set_xlim(0, 20.5)\n",
    "\n",
    "    # And finally, the meat\n",
    "    # for every integer from 0 up to the number of clusters\n",
    "    for i in clusters_to_plot:\n",
    "        \n",
    "        # Take just the datapoints whose cluters matches that integer        \n",
    "        cluster = data[(data.Cluster == i)][timepoints]\n",
    "        \n",
    "        # Calculate a mean and a standard deviation\n",
    "        mean = cluster.mean()\n",
    "        std = cluster.std()\n",
    "        \n",
    "        # Plot the time value on the x axis, the mean expression on the y, give it a label, and give it a color\n",
    "        ax.plot(xdata, mean, label=\"Cluster \" + str(i), color= colors(i))\n",
    "        \n",
    "        # Then, for every timepoint fill the space in between one deviaion below and above, \n",
    "        # make it 80% transparent, and give it the same color\n",
    "        plt.fill_between(xdata, mean-std, mean+std, alpha=0.2, facecolor = colors(i))\n",
    "    \n",
    "    # Lastly, slap a legend in the upper lft corner\n",
    "    plt.legend(ncol=1, loc = 'upper left');\n",
    "    return fig\n",
    "plotmeans(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like cluster 1 (orange) has already picked up a lot of the genes that increase in expression, but the other 4 clusters are all in a jumble, especially at the 15.5 and 18.5 hour timepoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try to plot a KDE curve of each of the clusters at each of the timepoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One note is that \"cluster_to_plot\" variable being set to None by default. \n",
    "def manykde(data, timepoints, clusters_to_plot = None):\n",
    "    fig = plt.figure(figsize=(15, 16))\n",
    "    ax = []\n",
    "    \n",
    "    # Here we are going to see if the user put anything in for the \"clusters_to_plot\" parameter\n",
    "    # And if they didn't, set it to range(k)\n",
    "    if clusters_to_plot == None:\n",
    "        clusters_to_plot = range(k)\n",
    "    # We had to do it this way because making \"range(k)\" the default would have \n",
    "    # used the k-value from when the function was defined, and not from when the function was called.\n",
    "    \n",
    "    # Moving on,\n",
    "\n",
    "    # For each timepoint get a number and the name of the timepoint\n",
    "    for i, time in enumerate(timepoints[1:]):\n",
    "\n",
    "        # Make a subplot in a 3-row, 2 column chart with the position being that number\n",
    "        # Add the subplot to a list\n",
    "        ax += [fig.add_subplot(3,2,i+1)]\n",
    "\n",
    "        # And then for each cluster\n",
    "        for j in clusters_to_plot:\n",
    "\n",
    "            # Get the points where the cluster matches the one we want to plot\n",
    "            s = data[data['Cluster'] == j][timepoints[i]]\n",
    "\n",
    "            # Plot a KDE curve\n",
    "            s.plot.kde(label=j, color=colors(j), ax=ax[i], linewidth = 3)\n",
    "\n",
    "            # Title, axis label, limits, legend\n",
    "            plt.title(\"{} hour timepoint\".format(time))\n",
    "            plt.xlabel(\"Expression\\nRatio\")\n",
    "            plt.ylim([0,2])\n",
    "            plt.xlim([-4, 4])\n",
    "            plt.legend()\n",
    "\n",
    "        # This handy-dandy little function automates the laying-out of the subgraphs, saving us the work\n",
    "        fig.tight_layout()\n",
    "    return fig, ax\n",
    "manykde(data, timepoints);\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, it looks like orange represents high-expression genes, and the rest are an overlapping jumble. One thing we didn't see earlier is that cluster 3, the red cluster, has a very narrow density at the beginning, timepoint. It also looks like clusters 0 and 2 are nigh-identical at each timepoint.\n",
    "\n",
    "Time to run the algorithm a few times, maybe 20 cycles?\n",
    "\n",
    "### Step 3+: Move the centers and repeat the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(25):\n",
    "    centerslist = c2p(data, timepoints)\n",
    "    data['Cluster'] = data[timepoints].apply(p2c, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 25 cycles everything should be clustered and we can try some visualizations to see how we've done.\n",
    "\n",
    "Just for the sake of variety let's try a plotting technique that's completely different: instead of taking all of the rows and plotting them - which would take longer than I want to wait - we can take a sample of, say, 200 from each cluster and plot the clusters individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manylines(data, samples = 200):\n",
    "    fig = plt.figure(frameon=False, figsize=(15, 15))\n",
    "\n",
    "    plt.title(\"Lineplots of {} semi-transparent samples from each cluster\".format(samples), y=1.05, fontsize='x-large')\n",
    "    plt.box('off')\n",
    "    plt.axis('off')\n",
    "\n",
    "    ax=[]\n",
    "    for i in range(k):\n",
    "        ax.append(fig.add_subplot(int(ceil(k/2)),2,i+1))\n",
    "\n",
    "        ax[i].set_ylim([-4,4])\n",
    "        ax[i].set_title(\"Cluster {}\".format(i))\n",
    "        plt.box('off')\n",
    "        plt.axis('off')\n",
    "        plt.setp(ax[i].get_xticklabels(), visible=False)\n",
    "\n",
    "        cluster = data[(data.Cluster == i)][timepoints].sample(samples)\n",
    "        cluster.loc[:, \"0\":\"20.5\"].T.plot(legend=None, color = [colors(i)], ax=ax[i], alpha = 0.1, linewidth=2)\n",
    "        \n",
    "manylines(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's almost like an art piece! We can clearly see patterns in each cluster:\n",
    "\n",
    "* Cluster 1 seems to be even, never changing much at all.\n",
    "\n",
    "* Cluster 2 shoots upwards\n",
    "\n",
    "* Cluster 3 jumps up and down wildly, it seems to have captured the more erratic points.\n",
    "\n",
    "* Cluster 4 drops down\n",
    "\n",
    "We can of course plot the KDEs and the means again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manykde(data, timepoints);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotmeans(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep, these confirm it: nice, clean separation!\n",
    "\n",
    "It looks like cluster1 (orange) and cluster 3 (red) are the genes most affected by starvation.\n",
    "\n",
    "Thanks to the clusters_to_plot parameter we built in, we can look at KDEs of just those clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manykde(data, timepoints, clusters_to_plot = [1, 3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not forget that we have the names of all of these genes, too: Let's look at a random sample of some of the named genes from cluster 1, the cluster that's highly expressed during starving conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['Cluster'] == 1) & data['GENE_NAME'].notnull()].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XBP1 is a cool name. What's that?\n",
    "\n",
    "We can look it up on [yeastgenome.org](https://www.yeastgenome.org/locus/S000001363) and it tells us that KGD1 is\n",
    "\n",
    "> not expressed during log phase of growth, but induced by stress or starvation during mitosis, and late in meiosis; represses 15% of all yeast genes as cells transition to quiescence; important for maintaining G1 arrest and for longevity of quiescent cells; \n",
    "\n",
    "Hey, there we go! A protein that gets expressed when yeast is starving, and it's job is to shut down 15% of all genes and maintain the longevity of cells that are \"quiescent\" (microbiologist-speak for hibernating).\n",
    "\n",
    "Our algorithim has prooved useful, and using just some microarray data has helped us sort 6000+ genes into categories, correctly identifying genes that are important to cellular starvation. We've done some real data science, albeit on a data set that's been around for a while on one of the most-studied organisms on the entire planet.\n",
    "\n",
    "That's been the main part of this tutorial, but I encourage you to stick around for a bonus segment where I will make some more sophisticated use of the MatPlotLib library to generate an animation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Plotting: Animation\n",
    "\n",
    "Let's take the full dataset and make a movie out of the clustering process!\n",
    "\n",
    "We can use then full-sized dataset, and find 6 clusters inside of it.\n",
    "\n",
    "Set K, get sample, make centers, assign clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 6\n",
    "sample = data.sample(k)\n",
    "centerslist = sample[timepoints].values\n",
    "data['Cluster'] = data[timepoints].apply(p2c, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use matplotlib's \"Func Animation\" module and we're going to animate the movement of the KDE lines for the final timepoint.\n",
    "\n",
    "This is going to be a lot of code, but to be honest most of it is formatting and comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This part is nothing new\n",
    "def clustering_animation(frames, interval = 250):\n",
    "    \n",
    "    # We're going to declare a few variables\n",
    "    labels = [\"Cluster {}\".format(i) for i in range(k)]\n",
    "    x = data.groupby(\"Cluster\").size()    \n",
    "    xdata = [float(t) for t in timepoints]\n",
    "    \n",
    "    # Then make the master figure and remove the box and axis from it\n",
    "    fig = plt.figure(figsize=(10, 15))\n",
    "    plt.box('off')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # The title here is long, so we're splitting it onto 2 lines. \n",
    "    # Python will treat everything that's inside of the same bracket \n",
    "    # as being on the same line.\n",
    "    # y = 1.05 moves the title up to 105% of it's normal height. \n",
    "    # This will give us room for a legend underneath of the title.\n",
    "    plt.title(\"Animation of K-means Clustering on a 7-dimensional Microarray Dataset\",\n",
    "              y=1.05, fontsize='x-large')  \n",
    "    \n",
    "    # For the first graph we'll do the means of the clusters\n",
    "    \n",
    "    # We'll create an axis, and call it \"ax1\"\n",
    "    ax1 = fig.add_subplot(3,1,1)\n",
    "    \n",
    "    # Remove those pesky spines and set the limits of the y-axis for consistency\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax1.set_ylim([-3,3])\n",
    "\n",
    "    # Add some titles and labels\n",
    "    ax1.set_title(\"Mean Values of Yeast Expression Ratios\")\n",
    "    ax1.set_xlabel(\"Time since innoculation\\n  /h\")\n",
    "    ax1.set_ylabel(\"Expression\\nRatio\", rotation = 0, labelpad = 25)\n",
    "    \n",
    "    # And now we are going to render the lines and add those lines to a list\n",
    "    # We're doing this so we can directly change the line data later, \n",
    "    # without having to redraw everything each time\n",
    "    lines = []\n",
    "    for i in range(k):\n",
    "        cluster = data[(data.Cluster == i)][timepoints]\n",
    "        mean = cluster.mean()\n",
    "        \n",
    "        #lobj means \"line object\", the trailing comma is really important here \n",
    "        # for reasons I won't get into\n",
    "        lobj, = ax1.plot(xdata, mean, color = colors(i), label=labels[i], lw=4)\n",
    "        # adding the line object to the list\n",
    "        lines.append(lobj)\n",
    "    \n",
    "    # The eagle-eyed among you will notice that we didn't draw the \n",
    "    # standard deviations yet. That's because the \"fill_between\" \n",
    "    # is not easy to change on-the-fly, so we're going to redraw it \n",
    "    # every frame instead of just editing the data like we do for the lines\n",
    "    \n",
    "    \n",
    "    # The second plot will be the KDEs\n",
    "    # Once again we're not bothering to render a first set of lines, \n",
    "    # The KDE lines are too much effort to edit on-the-fly\n",
    "    \n",
    "    # First is formatting. I absolutely could make this a function, and \n",
    "    # not re-write this but that might make it harder to tweak and tune things.\n",
    "    # and I want *you* to have the ability to fiddle with these settings yourself\n",
    "    ax2 = fig.add_subplot(3,1,2)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.set_ylim([0,2])\n",
    "    ax2.set_xlim([-4, 4])\n",
    "    ax2.set_title(\"KDE Plot of Expression Ratios at the 20.5 hour Timepoint\")\n",
    "    ax2.set_xlabel(\"Expression\\nRatio\")\n",
    "\n",
    "    # The third plot will be a bar graph of the number of genes in each cluster\n",
    "    ax3 = fig.add_subplot(3,1,3)\n",
    "    ax3.spines['top'].set_visible(False)\n",
    "    ax3.spines['right'].set_visible(False)\n",
    "    ax3.set_title(\"Number of Points in Each Cluster\")\n",
    "    ax3.set_ylabel(\"Number\", rotation = 0, labelpad = 30)\n",
    "    ax3.set_xlabel(\"Cluster\")\n",
    "    \n",
    "    # Here we create a bunch of rectangles which we will add to a list to update later.\n",
    "    rectangles = list(bar([i for i in range(k)], data.groupby(\"Cluster\").size(), \n",
    "                          color = [colors(i) for i in range(k)]))\n",
    "    \n",
    "    \n",
    "    # One final bit of formatting to create and modify a legend \n",
    "    leg = fig.legend(lines,                       # We'll use the list of lines as our representative image \n",
    "                     [i for i in range(k)],       # And title the lines as according to thier cluster number\n",
    "                     title = 'Cluster:',          # The legend will have its own title\n",
    "                     fontsize='large',            # We may as well make large text\n",
    "                     ncol=k,                      # The legend has k columns (one row)\n",
    "                     loc = 'center',              # The legend will be positioned based on its center\n",
    "                     bbox_to_anchor=(0.57, 0.96), # Here we fiddle with moving the legend around\n",
    "                     frameon = False)             # Finally we're removeing the box around the legend\n",
    "    \n",
    "    # Here we do a little more fiddling with the legend's title\n",
    "    leg._legend_box.align = \"left\"                # Left align the title text\n",
    "    leg.get_title().set_position((-55, -19))      # Move the text down to be beside the row of entries\n",
    "    leg.get_title().set_fontsize('large')         # And make the fontsize consistent with the entries\n",
    "    \n",
    "    # Finally we do that tight_layout thing, with an extra request for more \"height padding\" between subplots\n",
    "    plt.tight_layout(h_pad=3)\n",
    "    \n",
    "    \n",
    "    # The next piece is the code for updating each frame. \n",
    "    # \"i\" is just the framecount, we won't need it though.\n",
    "    def animate(i):\n",
    "        # We have to tell python that \"centerslist\" should be the list we declared outside of the function,\n",
    "        # Otherwise it will be confused when we update the variable later\n",
    "        global centerslist\n",
    "    \n",
    "        # We're going to update the rectangles first, because they are easy\n",
    "        # n is the number of datapoints in each cluster\n",
    "        n = data.groupby(\"Cluster\").size().values\n",
    "        \n",
    "        # we pair up rectangles and n-values, and then assign the rectangle heights to the n-value\n",
    "        for rectangle, n in zip(rectangles, n):\n",
    "            rectangle.set_height(n)\n",
    "\n",
    "        # These two lines delete the existing standard deviation fills and the KDE plot lines\n",
    "        ax1.collections = []\n",
    "        ax2.lines = []\n",
    "        \n",
    "        # Now we draw the line graph and KDE plot\n",
    "        # I'm being a bit sneaky here an piggybacking the kde-updates onto the same loop as the line-update\n",
    "        for j, line in enumerate(lines):\n",
    "            # Grab the mean, standard deviation for the cluster\n",
    "            cluster = data[(data.Cluster == j)][timepoints]\n",
    "            mean = cluster.mean()\n",
    "            std = cluster.std()\n",
    "            \n",
    "            # Then simply set the line data to the new data\n",
    "            line.set_data(xdata, mean)\n",
    "            \n",
    "            # And draw that fill-between\n",
    "            ax1.fill_between(xdata, mean-std, mean+std, facecolor = colors(j), alpha=0.1)\n",
    "            \n",
    "            # For the KDE plot we are going to get only the last timepoint\n",
    "            # In python asking a list for a negative index counts from the tail-end\n",
    "            s = cluster[timepoints[-1]]\n",
    "            \n",
    "            # Finally we plot the KDE curve for this loop\n",
    "            s.plot.kde(label=labels[j], color=colors(j), ax = ax2, linewidth = 3)\n",
    "            \n",
    "        # All that's left is to step through the clustering algorithim once\n",
    "        centerslist = c2p(data, timepoints)\n",
    "        data['Cluster'] = data[timepoints].apply(p2c, axis=1, raw=True)\n",
    "        \n",
    "        # And to return the updated rectangles and lines   \n",
    "        return rectangles + lines\n",
    "    \n",
    "    \n",
    "    # It's time to use the \"FuncAnimation\" function to build our movie\n",
    "    anim = animation.FuncAnimation(fig,               # \"fig\" is the fig we just built\n",
    "                                   animate,           # Animate is the function that updates the data\n",
    "                                   frames=frames,     # Frames is however many frames we put in the function call above\n",
    "                                   interval=interval, # Interval is the time to wait between frames (in milliseconds)\n",
    "                                   blit=True);        # blit will save a bit of time by only drawing things that change\n",
    "   \n",
    "    plt.close() # This closes down the figure\n",
    "    return anim # and then we return the finished animation!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew! That was a LOT of text.\n",
    "\n",
    "Before you get freaked out, remember that most of it was comments, and then most of the actual code was formatting.\n",
    "\n",
    "Anyways, it's time to wind down and watch a movie!\n",
    "\n",
    "*Note: If you are running this at home it may take a minute or so to render, if you get an error saying you have no moviewriter, your FFMPEG install is not set up correctly*\n",
    "\n",
    "*Note2: if for any reason this does not show up properly for you, please find an mp4 file on the GitHub*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_animation(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks at a glance like creating more clusters hasn't accomplished anything special, but let's take a look at that art-piece plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manylines(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the muddling of clusters 0, 1, 3, and 5 in the KDE plot, there are clear patterns to be seen in each cluster:\n",
    "* Cluster 0 slowly increases\n",
    "* Cluster 1 slowly decreases\n",
    "* Cluster 2 rapidly increases, and it's a lot more dispersed\n",
    "* Cluster 3 is all over the place\n",
    "* Cluster 4 sharply decreases\n",
    "* Cluster 5 is tame and barely moves at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it (for now), but if you're using this notebook on your own computer feel free to explore some of the genes in each cluster, maybe see why some seem to vary a lot while others don't by looking up different genes from each cluster in the yeast genome database.\n",
    "\n",
    "# Next time:\n",
    "\n",
    "One of the issues with this algorithm is that there's no sense of subtlety. Every point is either absolutely in or absolutely not in a cluster, but that's not always the best way to categorize things. Next time we'll investigate some ways of making these clusters \"soft\", as well as some statistical notions of clustering and ways to implement those in code. Stay Tuned!\n",
    "\n",
    "\n",
    "## Also in the pipeline:\n",
    "\n",
    "It was slightly annoying to have to decide on a K-value to sort with every time, wasn't it? Clustering algorithims like K-means are often called \"Flat\", as opposed to the \"Hierarchical\" clustering algorithims that create tiered trees such as this one:\n",
    "![Hierarchy](https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/CAH_tea_after_ACM01.png/603px-CAH_tea_after_ACM01.png)\n",
    "\n",
    "Where the data comes out as a tree, and you can look at each level of clustering. Look forward to a future installment about this kind of clustering algorithm.\n",
    "\n",
    "Note that those tend to take much, much longer to run, though, and people usually avoid them if they think that simply guessing a K-value would work about as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
